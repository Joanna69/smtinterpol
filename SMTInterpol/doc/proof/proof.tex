\documentclass[a4paper]{article}
\usepackage{xspace}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{pxfonts}
\usepackage{mathpartir}
\newcommand\mT{\mathcal{T}}
\newcommand\T{$\mT$\xspace}
\newcommand\Tp{$\mT'$\xspace}
\newcommand\mtp{\models_{\mT'}}
\newcommand\syms{\mathop{\mathit{syms}}}
\newcommand\si{SMTInterpol\xspace}
\newcommand\sversion{2.0}
\newcommand\siv{\si~\sversion}
\newcommand\gen[1]{\mathop{gen}\nolimits_{#1}}
\newcommand\dom{\mathop{dom}}
\newcommand\todo[1]{\textcolor{red}{TODO: #1}}
\newcommand\seqcomp{\circledwedge}
\newcommand\choicecomp{\circledvee}
\newcommand\quoted[1]{\ulcorner #1 \urcorner}

\title{Proposal: Proof System for \siv}
\author{J{\"u}rgen Christ \and Jochen Hoenicke}
\date{2017/09/27}
\begin{document}
\maketitle
\section{Motivation}
With the increase of complexity of the SMT solver \si, soundness gets a major
concern.  For satisfiable formulas, the solver can generate a model that
should satisfy all input formulas.  Checking this becomes hard when the input
contains quantifiers.  For unsatisfiable formulas, the solver can deliver a
proof of unsatisfiability, i.\,e., a derivation of \texttt{false} from the
input formulas.  This proof should contain all the steps needed to show
inconsistency of the current set of formulas.  To achieve this, a proof system
has to be given.  This system, however, should be as close to the operations
of the solver as possible.  Unfortunately, tracking every step of the solver
becomes challenging as the resulting proof might quickly grow to a size that is
too big to keep in memory.

In this document, we propose a proof system that completely captures
the inferences done by \si at an adequate level while keeping a
reasonably small memory overhead.  The main design goals of the system
are easy integration into \si and the possibility to reconstruct the
proof in another verification system, e.\,g., Isabelle.

\section{Proof System in \si}

The proof is done in three layers.  The first layer transforms input
clauses into a normal form, e.g. reducing the number of built-in
functions and simplifying some terms. This layer uses only equality
and equivalence rewrites on the whole formula and produces an
equivalent formula.

The second layer splits the formula into clauses and introduces
tautologies to define auxiliary literals.

The third and outermost layer is a resolution-based proof that uses
the input clauses and theory lemmas to proof the empty clause.
This concludes the proof.

In this section we present the three layers, starting with the
outermost layer.

\subsection{Partial Proof System}

Since the proofs in \si were originally only constructed to produce
interpolants, the proofs were cut at the CNF-level since interpolants
for the CNF are also valid interpolants for the original formula.
Furthermore, unsatisfiable cores can be extracted from the resolution
proof.  Since resolution proofs are sufficient for these two
techniques, the proof system keeps this separation.  That way, \si
won't have performance penalties on these techniques.  If, however, a
user wants to retrieve a complete proof, the conversion of the
original formula into CNF is also tracked.

The partial proof system for CNF consists of only three rules: clauses
created from input formulas (clause), theory lemmas
(lemma), and resolution steps (res).  The first two
are the leaves of the partial proof system and introduce valid
clauses.  The resolution rule represent the inner nodes of the proof
tree.

The \verb+@clause+ function takes as first argument, another proof
that shows that the clause follows from the input formulas.  This is
necessary since the input is usually not given in CNF.  The second
argument gives the resulting clause, so that the proof can be
reconstructed without following the subproof. Theory lemmas introduced
by \verb+@lemma+ are simple enough to not require a subproof, but
they take some auxiliary annotations tha make reconstructing the proof
easier.

The resolution function \verb+@res+ is
left-associative and has signature $@Proof\times@Proof\rightarrow@Proof$.  The
second proof is annotated with the pivot of the resolution.  This pivot
literal occurs negative in the first (the one not containing the pivot
annotation) and positive in the second argument.

\subsection{Formula Transformation and Simplification}

This section describes the proof steps to normalize the input formula.
This proof uses rules based on equality rewrites to show the
equivalence of the input formula with a simpler formula.  Then the
equality rule is used to derive the simpler formula from the input
formula.

\paragraph{Equality rule.}  This proof rule takes a Boolean term\footnote{We treat
  formulas as Boolean terms.} and an equality and produces a new term
where some occurrences of the left hand side of the equality are
replaced by the right hand side.
\[
\inferrule*[left=eq]{t_1 \\ t_1=t_2}{t_2}
\]

The eq rule is represented in SMTLIB as a function
\begin{verbatim}
(declare-fun @eq (@Proof @Proof) @Proof)
\end{verbatim}
This function takes a proof for $t_1$ and a proof for $t_1=t_2$ and
returns a proof for $t_2$.  The proved term $t_2$ is not provided but
can be easily computed by following the proof.

\paragraph{Lifting equalities.}  To rewrite only parts of a formula
\si uses the \textsc{congruence} and \textsc{exists} rule to lift
equalities from subterms.  Since all logical connectives in SMT-LIB
with the exception of quantifiers are Boolean functions, the
congruence rule can also be used for them.  Further there is the
transitivity rule to combine rewrites.  Finally the

\[
\inferrule*[left=trans]{t_1 = t_2 \\ t_2 = t_3}{t_1 = t_3}\qquad
\inferrule*[left=cong]{t = f(\dots t_i \dots) \\ t_i = t'_i}{t = f(\dots t'_i \dots)}\qquad
\inferrule*[left=exists]{F = G}{\exists x F = \exists x G}
\]

These rules are represented in SMTLIB as functions
\begin{verbatim}
:funs ((@trans @Proof @Proof @Proof :left-assoc)
       (@cong  @Proof @Proof @Proof :left-assoc)  ; left-assoc
       (@exists @Proof @Proof)
       (par (A) @refl A @Proof))
\end{verbatim}

This function \verb+@refl+ takes as argument a term $t$ and returns a
proof for $t=t$.  It is mainly used in the first argument of
\verb+@cong+ to rewrite a function application.  The functions
\verb+@trans+ and \verb+@cong+ take as arguments two proofs for the
terms as specified in the rules above and return a proof for the
resulting goal, which can easily be computed.  The function
\verb+@exists+ takes a proof for $F=G$ annotated with the list of term
variables \verb+((Sort x_1) ... (Sort x_n))+.  It returns the proof
for the exists equality.

\paragraph{Expanding definitions.}  A proof rule that justifies the expansion
of a defined function.  Let $n(\overline{t})$ be the application of
$\overline{t}$ to the function named $n$, and $d[\overline{t}]$ be the
definition where the free variables are substituted by the corresponding
terms.  Then, this rule justifies the replacement of $n(\overline{t})$ by its
definition.
\[
\inferrule*[left=ExpandDef]{ }{n(\overline{t}) = d[\overline{t}]}
\]

Some internal functions are also defined as defined functions,
e.g. the $abs x$ function is defined as $(ite (>= x 0) x (- x))$.

\paragraph{Expanding $n$-ary function applications.}  \si expands function
applications that use associativity, chainability, or the pairwise attribute.
The expansion transforms a left-associative function application
$f(t_1,t_2\ldots,t_n)$ with $n>2$ into $f(f(\ldots f(t_1,t_2),\ldots),t_n)$.
Similarly, right associative function applications $f(t_1,\ldots,t_{n-1},t_n)$
with $n>2$ are expanded into $f(t_1,f(\ldots,f(t_{n-1},t_n)))$.  Chainable
function applications $f(t_1,\ldots,t_n)$ are expanded into
$f(t_1,t_2)\land\ldots\land f(t_{n-1},t_n)$.

This step gets complicated since \si does not expand all such functions; it
keeps $n$-ary disjunctions, conjunctions, and implications.  Furthermore,
equalities and distinct applications are expanded after simplification.  
Hence, we will use different proof rules for these cases.

The remaining symbols are \texttt{xor} from the core theory, and the
arithmetic symbols \texttt{+}, \texttt{-}, \texttt{*}, the division symbols
\texttt{div} and \texttt{/}, and the comparison symbols \texttt{<},
\texttt{<=}, \texttt{>=}, and \texttt{>}.  For applications of these symbols
with more than 2 arguments, the following rewrite axiom will be introduced.
\[
\inferrule*[left=expand,right={$F'\equiv F$}]{ }{F = F'}
\]

\paragraph{Equality simplification.}
This set of rules justifies the simplification of an $n$-ary equality.  The
result depends on the simplification.  In general, it will be an equality with
up to $n$ arguments or a single term.  \si currently does the following
equality simplifications.
\begin{itemize}
\item Remove duplicated terms from the equality.  If the equality only
  contains duplicates, simplify to \verb+true+.
\item Simplify numeric equalities with different constants.
\item Simplify Boolean equalities:
  \begin{itemize}
  \item Simplify equalities containing \verb+true+ and \verb+false+ to
    \verb+false+.
  \item Simplify equalities containing \verb+true+ into conjunctions.
  \item Simplify equalities containing \verb+false+ into disjunctions.
  \end{itemize}
\end{itemize}

Equality simplification is split into several rules to ease proof validation.
\begin{mathpar}
  \inferrule*[left=TrueNotFalse,right={$\exists j,k\in I.\ t_j=true \land
      t_k=false$}]{ } {(=_{i\in I}\ t_i) = false}\\
  \inferrule*[left=ConstDiff,right={$\exists j,k\in I.\ t_j=c_j \land
      t_k=c_k\land c_j\neq c_k$}]{ } {(=_{i\in I}\ t_i) = false}\\
  \inferrule*[left=EqTrue,right={$\exists j\in I.\ t_j=true\land I'\subset
      I\land j\not\in I'$}]{ } {(=_{i\in I}\ t_i) = (not\ (and_{i'\in I'}\ (not\ t_{i'})))}\\
  \inferrule*[left=EqFalse,right={$\exists j\in I.\ t_j=false\land I'\subset
      I\land j\not\in I'$}]{ } {(=_{i\in I}\ t_i) = (not\ (or_{i'\in I'}\
    t_{i'}))}\\
  \inferrule*[left=EqSame,right={$\forall i,j\in I.\ t_i\equiv t_j$}]{
  }{(=_{i\in I}\ t_i) = true}\\
  \inferrule*[left=EqSimp,right={$I'\subset I\land |I'| = |\{t_i.\ i\in
      I\}|\land\{t_i.\ i\in I\} = \{t_j.\ j\in I'\} $}]{ }{(=_{i\in I}\ t_i) =
    (=_{i'\in I'}\ t_{i'})}\\
  \inferrule*[left=EqBinary]{(=_{i\in I}\ t_i) = (=_{i'\in I'}
    t_{i'})}{(=_{i\in I} t_i) = (not\ (or_{i',i''\in I'}\ (not\ (=\ t_{i'}\ t_{i''}))))}
\end{mathpar}

The last rule is used to convert an $n$-ary equality into a conjunction of
binary equalities.  Note that we represent the conjunction as a negated
disjunction as is done in the canonical form used by \si.

\paragraph{Distinct simplification.}
This set of rules is similar to the equality simplification rules.  It
contains axioms for the following cases.
\begin{itemize}
\item Simplify Boolean distinct-applications with more than two terms to
  \verb+false+.
\item Simplify binary Boolean distinct-applications where one argument is
  \verb+true+ resp.\ \verb+false+ to the other term or the negation of that
  term.
\item Simplify distinct-applications containing the same element multiple
  times to \verb+false+.
\end{itemize}

\begin{mathpar}
  \inferrule*[left=DistinctBool,right={$|I| > 2\land sort(t_i)=Bool$}]{
  }{(distinct_{i\in I}\ t_i) =
    false}\\ \inferrule*[left=DistinctSame,right={$\exists j,k\in I.\ t_j
      \equiv t_k \land j\neq k$}]{ }{(= distinct_{i\in I}\ t_i) =
    false}\\ \inferrule*[left=DistinctNeg,right={$t_0$ is negation of $t_1$}]{
  }{(distinct\ t_0\ t_1) =
    true}\\ \inferrule*[left=DistinctTrue,right={$t_i\equiv true$ for
      $i=0,1$}]{ }{(distinct\ t_0\ t_1) =
    (not\ t_{1-i})}\\ \inferrule*[left=DistinctFalse,right={$t_i\equiv false$
      for $i=0,1$}]{ }{(distinct\ t_0\ t_1) =
    t_{1-i}}\\
  \inferrule*[left=DistinctBoolEq,right={$sort(t_0)=sort(t_1)=Bool\land
      ((t_0',t_1')=(\lnot t_0,t_1)\lor(t_0',t_1')=(t_0,\lnot t_1))$}]{ }
  {(distinct\ t_0\ t_1) = (=\ t_0'\ t_1')}\\
  \inferrule*[left=DistinctBinary]{ }{(distinct_{i\in I}\ t_i) =
    (not\ (or_{i',i''\in I}\ (= t_{i'}\ t_{i''})))}
\end{mathpar}
The last rule is used to convert distinct applications into negated binary
equalities.

\paragraph{Negation simplification.}  \si simplifies negation to prevent
double negation and negations of \verb+true+ or \verb+false+.
\[
\inferrule*[left=NotSimp,right={$F'\equiv
    \left\{\begin{array}{l@{\quad\mbox{if}\quad}l}false & F\equiv true\\true &
    F\equiv false\\ G&F\equiv(not\ G)\end{array}\right.$}]{ }
           {(not\ F) = F'}
\]

\paragraph{Disjunction simplification.}  \si simplifies disjunctions by removing
duplicates or falsety and simplifying trivial tautologies to $true$.  We
justify these steps by two axioms.
\begin{mathpar}
  \inferrule*[left=OrSimp,right={where
      $I'\subset I$ and $\{t_i |i\in I'\} = \{t_i|i\in I\} \setminus \{false\}$}]
     { }{(or_{i\in I}\ t_i) = (or_{i\in I'}\ t_i)}\\
  \inferrule*[left=OrTaut,right={$\exists i\in I.\ t_i\equiv\ true\lor\exists
      i,i'\in I.\ t_i\equiv\ (not\ t_i')$}]{ }{(or_{i\in I}\ t_i) = true}
\end{mathpar}
If $I' = \{i'\}$ contains only one element, $(or_{i\in I'}\ t_i)$ stands for $t_i'$.
if $I'$ is empty $(or_{i\in I'}\ t_i)$ stands for $false$.

\paragraph{If-then-else simplification.}  \si applies trivial Boolean
simplification to if-then-else terms.  These simplifications are again
justified by axioms.
\begin{mathpar}
  \inferrule*[left=IteTrue]{ }{(ite\ true\ t_1\ t_2) = t_1}\quad
  \inferrule*[left=IteFalse]{ }{(ite\ false\ t_1\ t_2) = t_2}\\
  \inferrule*[left=IteSame]{ }{(ite\ t_0\ t_1\ t_1) = t_1}\\
  \inferrule*[left=IteBool1]{ }{(ite\ t_0\ true\ false) = t_0}\quad
  \inferrule*[left=IteBool2]{ }{(ite\ t_0\ false\ true) = (not\ t_0)}\\
  \inferrule*[left=IteBool3]{ }{(ite\ t_0\ true\ t_2) = (or\ t_0\ t_2)}\\
  \inferrule*[left=IteBool4]{ }{(ite\ t_0\ false\ t_2) =
    (not\ (or\ t_0\ (not\ t_2)))}\\
  \inferrule*[left=IteBool5]{ }{(ite\ t_0\ t_1\ true) = (or\ (not\ t_0)\ t_1)}\\
  \inferrule*[left=IteBool6]{ }{(ite\ t_0\ t_1\ false) =
    (not\ (or\ (not\ t_0)\ (not\ t_1)))}
\end{mathpar}

\paragraph{Removal of Boolean connectives.}  Before producing clauses, \si
converts the formula into an equivalent form with less Boolean connectives.
These conversion steps are justified by several proof axioms.
\begin{mathpar}
  \inferrule*[left=AndToOr]{ }{(and\ t_i) = (not\ (or\ (not\ t_i)))}\\
  \inferrule*[left=XorToDistinct]{ }{(xor\ t_1\ t_2) = (distinct\ t_1\ t_2)}\\
  \inferrule*[left=ImpToOr]{ }{(implies_{i\in I}\ t_i\ t) = (or_{i\in
      I}\ t\ (not\ t_i))}\\

\end{mathpar}
These axioms might be followed by simplification steps for \verb+or+ or
\verb+distinct+ to further transform the resulting formula.

\paragraph{Removing Annotations.}  This axiom justifies the equality
between \verb+F+ and \verb+(! F :annotations)+, i.\,e., the semantic
equivalence of these terms.
\[
\inferrule*[left=strip]{ }{(!\ F\ :\!annotations) = F}
\]

\paragraph{Normalizing arithmetic expressions.}  \si normalizes arithmetic
expressions into a canonical form.  This canonical form is then used to
transform a term into an internal form.  With this set of axioms, we describe
the transformation of a term in the input into canonical form.
\begin{mathpar}
  \inferrule*[left=CanonicalSum,right={$t' \cong t$}]{ }{t =
    t'}\\
  \inferrule*[left=LeqToLeq0,right={$t' \cong t_1-t_2$}]{
    }{(<=\ t_1\ t_2) = (<=\ t'\ 0)}\\
  \inferrule*[left=LtToLeq0,right={$t' \cong t_2-t_1$}]{
    }{(<\ t_1\ t_2) = (not\ (<=\ t'\ 0))}\\
  \inferrule*[left=GeqToLeq0,right={$t' \cong t_2-t_1$}]{
    }{(>=\ t_1\ t_2) = (<=\ t'\ 0)}\\
  \inferrule*[left=GtToLeq0,right={$t' \cong t_1-t_2$}]{
    }{(>\ t_1\ t_2) = (not\ (<=\ t'\ 0))}
\end{mathpar}
\si computes the polynomial sum of two polynomials by summing up identical
monomials and cancel them, if the factors sum to 0.  As example, consider
$t_1\equiv (+\ (*\ 3\ x)\ (*\ 2\ y))$ and $t_2\equiv (+\ y\ (*\ 3\ x))$.  The
monomials in these terms are $x$ and $y$.  Computing $t_1-t_2$, we cancel $x$
and sum up the factors of $y$, i.\,e., we compute $2-1=1$ and get
$t_1-t_2\equiv y$.  Note that \si does not produce any intermediate proof
steps to justify associativity or commutativity of arithmetic operators.

\paragraph{Arithmetic simplification.}  \si simplifies arithmetic comparisons
after transforming them into normal form.
\begin{mathpar}
  \inferrule*[left=LeqTrue,right={$c \leq 0$}]{ }{(<=\ c\ 0) = true}\quad
  \inferrule*[left=LeqFalse,right={$c > 0$}]{ }{(<=\ c\ 0) = false}
\end{mathpar}

\paragraph{Divisible rewrite.}  This axiom justifies the rewrite of
\verb+((_ divisible n) t)+ into \verb+(= t (* n (div t n)))+.  Hence, it
removes the divisible operator from the formula.  Furthermore, if $t$ is a
constant, this rules justifies the static evaluation of this construct.
\begin{mathpar}
\inferrule*[left=divisible]{ }{((\_\ divisible\ 1)\ t) = true}\\
\inferrule*[left=divisible,right={$t$ is integer constant not divisible by
    $n$}]{ }{((\_\ divisible\ n)\ t) = false}\\
\inferrule*[left=divisible,right={$t$ is integer constant divisible by $n$}]{
}{((\_\ divisible\ n)\ t) = true}\\
\inferrule*[left=divisible]{ }{((\_\ divisible\ n)\ t) =
  (=\ t\ (*\ n\ (div\ t\ n)))}
\end{mathpar}

\paragraph{Division rewrites.}  Integer division can be simplified if either
the divisor is $1$ or $-1$, or the dividend and the divisor are constant.  \si
uses different rewrite axioms for these.  The rules mimic the SMTLIB semantic
of ``rounding towards 0''.
\begin{mathpar}
  \inferrule*[left=div1]{ }{(div\ c\ 1) = c}\quad
  \inferrule*[left=div-1,right={$d\equiv-c$}]{ }{(div\ c\ (-\ 1)) = d}\\
  \inferrule*[left=divConst,right={$d\equiv\left\{\begin{array}{l@{\ \mbox{if}\ }l}\lfloor\frac{c_1}{c_2}\rfloor&c_2>0\\ \lceil\frac{c_1}{c_2}\rceil&c_2<0\end{array}\right.$}]{ }{(div\ c_1\ c_2) = d}
\end{mathpar}

\paragraph{Modulo rewrites.}  This axiom justifies the rewrite of
\verb+(mod x y)+.  The result of the rewrite depends on the values of 
\verb+x+ and \verb+y+.  If \verb+y+ is either $1$ or $-1$, the result is 0, if
\verb+x+ is constant, and \verb+y+ is a constant different from $0$, \si
replaces the modulo by the correct value.  Otherwise, if \verb+y+ is a
constant different from $0$, the modulo is rewritten into
\verb+(- x (* y (div x y)))+.  The rules mimic the SMTLIB semantic of the
Euclidian definition of div and mod.
\begin{mathpar}
  \inferrule*[left=mod1]{ }{(mod\ c\ 1) = 0}\quad
  \inferrule*[left=mod-1]{ }{(mod\ c\ (-\ 1)) = 0}\\
  \inferrule*[left=modConst,right={$d\equiv\left\{\begin{array}{l@{\ \mbox{if}\ }l}c_1-c_2\lfloor\frac{c_1}{c_2}\rfloor&c_2>0\\ c_1-c_2\lceil\frac{c_1}{c_2}\rceil&c_2<0\end{array}\right.$}]{ }{(mod\ c_1\ c_2) = d}\\
  \inferrule*[left=modulo]{ }{(mod\ x\ y) = (+\ x\ (*\ (- y)\ (div\ x\ y)))}
\end{mathpar}
Note that the right hand side of the \verb+modulo+ rule is equivalent to the
internal form of $(-\ x\ (*\ y\ (div\ x\ y)))$.  This saves one additional
rewrite step into canonical form.

\paragraph{Integer injection.}  The \verb+to_int+ operator can be used to
convert a real term into an integer.  The SMTLIB semantic describes this
conversion as the standard floor operation on reals.  If this is applied to a
constant, \si replaces the application by the result.
\[
\inferrule*[left=toInt,right={$v\equiv\lfloor r\rfloor$}]{ }{(to\_int\ r) = v}
\]

\paragraph{Real injection.}  The \verb+to_real+ operator can be used to
convert an integer term into a real term.  This is essentially no change in
the meaning of this term since any integer term is also a real term, but the
term representation changes.  For constants, we statically evaluate the
application by appending a \verb+.0+ to the original constant.
\[
\inferrule*[left=toReal]{ }{(to\_real c) = c.0}
\]

\paragraph{Array rewrites.}  The theory of arrays contains several constructs
that can be the target of rewrites.  \si implements the following rewrites for
arrays:
\begin{itemize}
\item Static store-over-store:  If a store overwrites the value of a directly
  adjacent store term, the inner store term is removed.  This is justified by
  the following rewrite axiom.
\[
\inferrule*[left=storeOverStore]{ }{(store\ (store\ a\ i\ v_1)\ i\ v_2) =
  (store\ a\ i\ v_2)}
\]
\item Static select-over-store:  If the select-over-store axiom can be
  statically evaluated, \si replaces the application of the term by its
  conclusion.  Static evaluation can be done if the index terms are known to
  be equivalent or distinct.  Since \si does not include congruence closure in
  the simplification phase, it only simplifies if the index terms are
  syntactically equal or numerical.  The rewrite is justified by the following
  axioms:
\begin{mathpar}
  \inferrule*[left=selectOverStore]{ }{(select\ (store\ a\ i\ v)\ i) = v}\\
  \inferrule*[left=selectOverStore,right={$c_1\neq c_2$}]{
  }{(select\ (store\ a\ c_1\ v)\ c_2) = (select\ a\ c_2)}
\end{mathpar}
\item Store rewrite:  In the array theory it is possible to have store terms
  that only describe values for the base array.  In this case, the store term
  can be rewritten into a select.  The following axiom justifies this rewrite.
\begin{mathpar}
\inferrule*[left=storeRewrite]{ }{(=\ a\ (store\ a\ i\ v)) =
  (=\ (select\ a\ i)\ v)}\\
\inferrule*[left=storeRewrite]{ }{(=\ (store\ a\ i\ v)\ a) =
  (=\ (select\ a\ i)\ v)}
\end{mathpar}
\end{itemize}

\subsection{Building CNF}
After normalization and simplification, \si produces CNF from the modified
input formula.  The proof rules described before justify the equivalence of
the input assertion and the canonical form.  The rules in this section justify
the transformation of the canonical form into an equisatisfiable CNF.  The
basic operations performed during this process are creation of literals from
the leaves of the Boolean part of the term, structural splitting of the
formula, and introduction of auxiliary atoms for a Plaisted--Greenbaum- or
Tseitin-style encoding of the input formula.

\paragraph{Structural splitting.}  
The top-level structure of the canonical form now corresponds to a term-DAG
containing only negation, disjunction, equality between Boolean terms,
if-then-else terms, and terms corresponding to atoms.  To compute CNF from
this DAG, \si splits the DAG according to the remaining structure.  The rule
mostly used by \si splits conjunctions into one of the individual conjuncts.
The negations produced by this rule might be further simplified using
\texttt{NotSimp}.  Hence, an equality folding steps might follow directly upon
an application of this rule.

\begin{mathpar}
  \inferrule*[left=NotOrElim,right={$j\in I$}]{(not\ (or_{i\in
      I}\ t_i))}{(not\ t_j)}\quad
\end{mathpar}

Equalities between Boolean terms and if-then-else terms are not transformed by
this rule.  Note that the equalities are binary since we are dealing with
canonical form.  The rules to remove such connectives create pseudo-clauses,
i.\,e., clauses that are not actually inserted into the clause database of
\si, but further processed by rewrite rules.  The negations might be
simplified by \texttt{NotSimp} and an equality folding step.
\begin{mathpar}
  \inferrule*[left={=+1}]{(=\ F_1\ F_2)}{(or\ F_1\ (not\ F_2))}\quad
  \inferrule*[left={=+2}]{(=\ F_1\ F_2)}{(or\ (not\ F_1)\ F_2)}\\
  \inferrule*[left={=-1}]{(not\ (=\ F_1\ F_2))}{(or\ F_1\ F_2)}\quad
  \inferrule*[left={=-2}]{(not\ (=\ F_1\ F_2))}{(or\ (not\ F_1)\ (not\ F_2))}\\
  \inferrule*[left={ite+1}]{(ite\ F_1\ F_2\ F_3)}{(or\ (not\ F_1) F_2)}\quad
  \inferrule*[left={ite+2}]{(ite\ F_1\ F_2\ F_3)}{(or\ F_1 F_3)}\\
  \inferrule*[left={ite-1}]{(not\ (ite\ F_1\ F_2\ F_3))}{(or\ (not\ F_1) (not\ F_2))}\quad
  \inferrule*[left={ite-2}]{(not\ (ite\ F_1\ F_2\ F_3))}{(or\ F_1 (not\ F_3))}
\end{mathpar}

\paragraph{Building Literals.}
After splitting the term-DAG into clauses, every term in every clause is
transformed into a literal\footnote{This process sometimes is called
  \emph{internalization}.}.  This step might slightly change the term
representation due to implicit application of symmetry or associativity
axioms, or might even simplify the term to \texttt{false} if theory reasoning
allows further simplification, e.\,g., in the case of linear equalities over
the integer (e.\, g., $2x=1$).  We justify this step by another rewrite rule.
\[
\inferrule*[left=intern,right={$F\equiv F'$}]{ }{F = F'}
\]
This axiom also justifies the introduction of a proxy literal as needed by
Plaisted--Greenbaum- or Tseitin-style CNF encoding. The proxy literal captures
the truth value of the corresponding sub-formula.  The proxy literal
\emph{quotes} the sub-formula and is used as a regular literal in the
remaining proof.  \si highlights quotation of a sub-formula by wrapping it in
a \texttt{:quoted} annotation, e.\,g., $(!\ (or\ A\ B)\ :quoted)$ is the proxy
literal for $(or\ A\ B)$.  Note that \si does not produce proxy literals for
negated formulas but negates the proxy for the positive formula instead.

\paragraph{Flattening nested disjunctions.}
Clauses are built from disjunctions.  So far, the proof system does not care
about nesting of these disjunctions.  However, the \texttt{flatten} rule is
used to transform the nested disjunction into one disjunction without the
nesting.  It works recursively on the nested disjunctions.
\todo{The way it is implemented right now, it simply replaces a nested or by
  its arguments in a top-down manner.  While this is nice for the reader, it
  is unnecessarily complex for the implementation.  Is this order really
  necessary or can we just move the disjuncts of nested disjunctions to the
  back of the result?}

\paragraph{Building clauses.}
The \texttt{intern} rules induces another rewrite system.
This system is again applied by the equality folding rule \texttt{eq}.  The
resulting formula might still contain nested disjunctions.  The rule
\texttt{clause} permutes the resulting clause.
\begin{mathpar}
\inferrule*[left=clause]{(or\ t_1\ldots t_n)}{(or\ t_i')}
\end{mathpar}
Note that we do not use $0$-ary or unary or-applications.  Instead, we write
\texttt{false} or the unit literal, respectively.

\todo{This rule now only serves the purposes of permuting a clause from its
  derivation and to visualize the clauses before they are fed into the
  resolution proof.  In my opinion, permuting is unnecessary since it does not
  change validity of the proof.  Seeing the clause before they are fed into
  the resolution proof is nice if one only wants to track the resolution
  steps.  But then why use the full proof mode?  For proper proof validation,
  seeing the clause is actually unnecessary unless the derived clause deviates
  from its derivation.  However, I expect the resolution proof to fail in this
  case as well.  So I vote for the removal of this rule since all useful
  functionality has been replaced by a combination of flatten and simpOr.}

\paragraph{Tautologies.}  For some introduced terms a corresponding tautology
is created during the transformation into CNF.  These tautologies are
clauses that are annotated with the kind of the tautology.  

Table~\ref{tab:tautforms} lists the different kinds of tautologies present
in \si.  Here, $\quoted{F}$ denotes the proxy
literal\footnote{These literals appear in proofs with the annotation
  \texttt{:quoted}.} for formula $F$, $F$ denotes formulas, $t$ denotes terms,
and $t_F$ denotes the term corresponding to $F$\footnote{In the proof returned
  by \si, $t_F$ and $F$ are equal.  The distinction is only done internally
  since $F$ is a Boolean term handled by the DPLL core and $t_F$ is the term
  used by congruence closure.}.
\si internally collects the disjunctive parts of the individual formulas.  The
\texttt{termITE} tautology is also used when term if-then-else trees are
minimized, i.\,e., when the then- or else-part of the if-then-else is an
if-then-else again.  Then, only one term might be used and the $t$ in the
result is one leaf or a shared if-then-else tree that is a sub-term of the
left-hand-side of the equality.
\begin{table}[htbp]
  \begin{tabular}{l|l}
    Kind & Clause\\\hline
    trueNotFalse & $true\neq false$\\
    or+ & $\neg\quoted{F_1\lor \ldots \lor F_n}\lor F_1\lor \ldots\lor F_n$\\
    or- & $\quoted{F_1\lor \ldots \lor F_n}\lor \neg F_i$\\
    ite+1 & $\neg\quoted{if F_1 then F_2 else F_3}\lor\neg F_1\lor F_2$\\
    ite+2 & $\neg\quoted{if F_1 then F_2 else F_3}\lor F_1\lor F_3$\\
    ite+Red & $\neg\quoted{if F_1 then F_2 else F_3}\lor F_2\lor F_3$\\
    ite-1 & $\quoted{if F_1 then F_2 else F_3}\lor\neg F_1\lor\neg F_2$\\
    ite-2 & $\quoted{if F_1 then F_2 else F_3}\lor F_1\lor\neg F_3$\\
    ite-Red & $\quoted{if F_1 then F_2 else F_3}\lor\neg F_2\lor\neg F_3$\\
    =+1 & $\neg\quoted{F_1=F_2}\lor F_1\lor\neg F_2$\\
    =+2 & $\neg\quoted{F_1=F_2}\lor\neg F_1\lor F_2$\\
    =-1 & $\quoted{F_1=F_2}\lor F_1\lor F_2$\\
    =-2 & $\quoted{F_1=F_2}\lor\neg F_1\lor\neg F_2$\\
    excludedMiddle1 & $\neg F\lor t_F = true$\\
    excludedMiddle2 & $F\lor t_F = false$\\
    termITE & $\neg F_1\lor\ldots\lor\neg F_n if F then t_1 else t_2 = t$\\
    divLow & $d\cdot (x\div d) - x \leq 0$\\
    divHigh & $\neg (|d| - x + d\cdot (x\div d)\leq 0)$\\
    toIntLow & $to\_real(to\_int(x)) - x \leq 0$\\
    toIntHigh & $\neg (1 - x + to\_real(to\_int(x))\leq 0)$\\
    eq & $c_1t_1=c_2t_2\lor
    \pm\frac{c_1}{gcd(c_1,c_2)}t_1\mp\frac{c_2}{gcd(c_1,c_2)}t_2\neq 0$ or\\
    &$c_1t_1\neq c_2t_2\lor \pm\frac{c_1}{gcd(c_1,c_2)}t_1\mp\frac{c_2}{gcd(c_1,c_2)}t_2=0$
  \end{tabular}
  \caption{\label{tab:tautforms}Different Kinds of Tautology Clauses.}
\end{table}

\section{Implementation}
After presenting the set of rules used by \si, we now describe some
major issues to ensure soundness/correctness of the generated proofs.

In \si, we consider $let$ as syntactic sugar.  Let is necessary to
compactly represent a huge proof where parts, e.g. larger subproofs,
are used multiple times in the proof.  Conceptually every let term is
expanded and two let terms that expand to the same term are considered
to be identical.

\subsection{Basic Proof Rules}

On a high level \si uses the proof rules defined below.
The following four proof rules introduce valid formulas:
\textsc{lemma}, \textsc{tautology}, \textsc{asserted}, \textsc{assumption}.
Lemma is used for theory lemmas.  Tautology is used by the
pre-processor to introduce auxiliary literals.  Asserted is used to
introduce formulas that were asserted in the script and assumption is
used to introduce assumption literals.  Additional we have the
following proof rules.

\[
\inferrule*[left=res]{C_1 \lor \ell \\ C_2 \lor \lnot \ell}{C_1 \lor C_2}\qquad
\inferrule*[left=eq]{t_1 \\ t_1 = t_2}{t_2}\qquad
\inferrule*[left=exists]{F = G}{\exists x F = \exists x G}
\]
\[
\inferrule*[left=trans]{t_1 = t_2 \\ t_2 = t_3}{t_1 = t_3}\qquad
\inferrule*[left=cong]{t = f(\dots t_i \dots) \\ t_i = t'_i}{t = f(\dots t'_i \dots)}\qquad
\inferrule*[left=refl]{}{t = t}
\]
\[
\inferrule*[left=split,right={where $F$ implies $G$}]{F}{G}\qquad
\inferrule*[left=rewrite,right={where $t_1 = t_2$ is a tautology}]{}{t_1 = t_2}
\]


\subsection{Proof Tree Structure}
The proof tree consist of three parts:
\begin{enumerate}
\item transforming input into canonical form,\label{it:tocan}
\item transforming canoncial form into clausal form,\label{it:tocnf} and
\item the resolution proof\label{it:resproof}.
\end{enumerate}
The proof tree structure will correspond to this ordering.
\[
\inferrule*[Left=res,sep=1em]{
  \inferrule*[Left=Eq]{
    \inferrule*[Left=split]{
    \inferrule*[Left=Eq]{
      F_{input} \\ (=\ t_i\ t_i')}
               {F_{canonical}}}{(or_{j\in J_1}\ t_j)} \\ (=\ t_j\ t_j')}{(or\ t_i)}
  \\ \ldots \\
  \inferrule*[Left=eq]{
    \inferrule*[Left=split]{
      \inferrule*[Left=Eq]{
        F_{input} \\ (=\ t_i\ t_i')}
                 {F_{canonical}}}{(or_{j\in J_n}\ t_j)} \\ (=\ t_j\ t_j')}{(or\ t_i)}
  \\ \mathcal{T}\!-lemmas
}{\bot}
\]
\todo{Should we include the flatten-rule in this picture?}

Note that the conversion steps from $F_{input}$ into $F_{canonical}$
for one input formula can appear multiple times in the proof and will
be eliminated by common subexpression elimination (let).  Only the step
producing the clauses from the canonical formula will change.
Furthermore note that we do not give a derivation for theory lemmas.
These clauses are annotated with enough information to reconstruct a
proof of validity.

\section{Proof Terms in \si}
Proofs are represented as terms of sort \verb+@Proof+ in \si.  Note that the
\verb+@+ is part of the name of the sort to prevent unintentional clashes with
user-defined sorts since \verb+@+ and \verb+.+ are reserved for solvers in the
SMTLIB standard.

There are several rules to convert a Boolean formula into a proof.  In the
following we will show these rules and discuss their annotations.

\paragraph{Asserted terms.}  Terms asserted by the users are converted into
proof objects by the \verb+@asserted+ function.  This function has type
$Bool\rightarrow @Proof$.  The formula still contains all annotations.
Especially the \verb+:named+ annotation is kept and can be used to recognize
the input formula.

Adding specialized names to asserted formulas to simplify recognition is not a
good idea.  Naming a formula has some side-effects and leads to an application
of the \verb+strip+-rule.  While the latter might not be too bad, we can avoid
the side-effects by annotating the formula with a keyword different from
\verb+:named+ (or \verb+:pattern+, or \verb+:pat+).  This new keyword has no
meaning to the solver.  Hence it will be ignored (except for stripping it from
the formula) and can be used to recognize the input formula.

\paragraph{Rewrites.}  Most of the rules presented above introduce equalities
that are later used to rewrite an input term.  To introduce these axioms into
the proof tree, \si uses the \verb+@rewrite+ function which introduces a
Boolean formula $old = new$ to rewrite all occurrences of $old$ in a formula
into $new$.  The function has signature $Bool\rightarrow @Proof$.  The
argument to the \verb+@rewrite+ function is annotated with the name of the
rewrite axiom used.  Similarly to \verb+@rewrite+, the \verb+@intern+ function
introduces rewrite equalities.  It has the same signature, but the Boolean
term will not be annotated.

\paragraph{Structural Splitting.}  If the Boolean structure of the input is
more complex and cannot be transformed into disjunctive form during
canonicalization, \si uses structural splitting.  The proof tree uses the
\verb+@split+ function to describe a structural split.  This function has
signature $@Proof\times Bool\rightarrow @Proof$ where the first argument is
annotated with the rule used in this splitting step and the second argument is
the result of the split.

Splitting conjunctions is a special case here.  \si might insert another
\verb+@eq+ rewrite to rewrite double negations directly after the rewrite.
The reason for this asymmetric behavior in structural splitting is that after
splitting a conjunction, we might directly split another time on either
another (nested) conjunction, or a different operator.  Hence, if a
conjunction split produces a double negation, the next proof step will be an
equality rewrite that replaces the double negation.

\paragraph{Applying rewrites.}  The \verb+@eq+ function is used to apply
rewrites to a proof.  This function is left-associative and has signature
$@Proof\times@Proof\rightarrow @Proof$.  This signature, however, is not
strong enough to express all details.  The second proof is a proof of a
rewrite equality that is introduced with \verb+@rewrite+ or \verb+@intern+
while the first proof can be \verb+@asserted+ or a derivation sequence.

\paragraph{Creating literals}  After converting an input formula in canonical
form and possibly splitting it, \si creates clauses.  The input to this
process is a (possibly nested) disjunction.  For every disjunct, a literal
will be created.  This literal should replace the term in the (flattened)
clause.  We distinguish different kinds of literals, but all literals are
introduced into the proof tree using the \verb+@intern+ function with
signature $Bool\rightarrow @Proof$.  Essentially, this function is the
justification for another rewrite axiom.

Depending on the literal, the \verb+@intern+ function might have different
effects:
\begin{description}
\item[Proxy Literal] For a proxy literal, the term is simply wrapped by the
  annotation \verb+:quoted+.
\item[Equalities] An equality $(=\ t_1\ t_2)$ might be transformed into
  $(=\ t_2\ t_1)$ by an implicit application of symmetry.  This usually
  happens to unify two literals, i.\,e., when a literal for the latter form
  already exists.  If the equality is a numeric equality, it might be
  transformed into its numeric form $(=\ (-\ t_1\ t_2)\ 0)$.  Note that during
  this conversion, arithmetic simplification and symmetry might be used.

  The equality might be transformed to $true$ if it holds trivially, or
  $false$ if it cannot hold trivially (e.\,g., $x=x+1$) or due to a failed GCD
  test over the integers (e.\,g., $2x=1$).  In these cases, no literal will be
  created.
\item[Inequalities] Inequalities of the form $(<=\ t\ 0)$ will be transformed
  into inequality literals of the form $(<=\ t'\ 0)$ where $t'=t$ is the
  result of applying commutativity to (sub-terms of) $t$.
\end{description}

\paragraph{Tautologies.}  Various constructs create tautologies during the
transformation into CNF.  These tautologies are clauses that are annotated
with the kind of the tautology.  The \verb+@tautology+ function transforms a
clause annotated with the kind of tautology into a proof.  The function has
signature $Bool\rightarrow @Proof$.

\paragraph{Lemmas.}  The resolution proof produced by \si contains lemmas
created by theory solvers.  These lemmas are valid Boolean terms.  The
function \verb+@lemma+ transforms the clause into a proof term.  Hence, it has
signature $Bool\rightarrow @Proof$.

The lemmas are annotated with a theory identifier and further,
theory-specific annotations.  The theory identifiers currently supported are
\verb+LA+ and \verb+CC+.  Proofs from the LA-solver additionally carry the
coefficients used by the solver when applying Farkas' lemma to the input
problem.  The coefficients are given in the same order the negated literals
appear in the lemma.  Proofs from congruence closure are annotated with the
paths through the congruence graph and, optionally, a disequality that is
violated.

Some lemmas might be annotated with \verb+:trichotomy+.  This annotation is
used for a clause of the form $t_1=t_2\lor t_1<t_2\lor t_1 > t_2$.  Note that
this clause is a special form of theory lemma that justifies a case split in
the linear arithmetic solver if $t_1$ and $t_2$ are not equal.

\paragraph{Creating clauses.}  The final step in the conversion of an input
formula into CNF is the creation of clauses from disjunctive parts of the
input formula.  We get these parts by structural splitting of the input
formula that is proven by the \verb+@split+ function.

Once a (possibly nested) disjunction is created by a split \si produces a
clause for this disjunction.  First, if needed, the disjunction is flattened.
This replaces all nested disjunctions by their disjuncts.  Then, the
individual disjuncts are replaced by literals.  This step is justified by the
\verb+@eq+-rule that applies the rewrite system whose rewrite rules are stated
by \verb+@intern+-axioms.   Note that \verb+@intern+ might rewrite a formula
into a negated formula.  If this is the case and the resulting literal should
be negated once more, \si will add a negation simplification rewrite.
Furthermore, some disjuncts might be internalized to false\footnote{Currently
  this only happens for unsatisfiable integer equalities, e.~g., $2x=1$} and
the disjunction might contain duplicated terms due to flattening.  In these
cases, the \verb+orSimp+ rule is used to compute the resulting clause.

Since \si internally permutes the literals in a clause, a final proof step is
used to represent the resulting clause.
This step is represented by the \verb+@clause+
function in the proof tree.  This function has
signature $@Proof\times Bool\rightarrow@Proof$.
It is correct, if the first argument is a proof for a (possibly nested)
disjunction that can be flattened and reordered into the second argument.

\paragraph{Showing Results.}  The rules in SMTLIB format produce an implicit
result.  To overcome this restriction, \si appends the results of structural
splitting and clause creation to the rules as described above.

\paragraph{Compressing Proofs.}  Besides the compression possible by
exploiting left-associativity of \verb+@eq+ and \verb+@res+, we can further
compress the proof tree.  If no rewrite takes place to transform a formula
into canonical form or to create a clause, the rule \verb+@eq+ will be
suppressed.

\section{Example Proof}
In this section, we will see an except of a proof produced by \si for the
formula $2x=z \land 2y + 1 = z$ where the variables $x,y,z$ are integer
variables.  We will focus on the steps taken by \si to transform this formula
into a set of clauses and omit the resolution refutation\footnote{The
  refutation needs two lemmas from the theory of linear integer arithmetic and
  some resolution steps.  The actual proof depends on the proof transformation
  used when printing the proof.  The derivation of the clauses, however, is
  not affected by the proof transformation.}.

We assume the formula is given in SMTLIB syntax as
\begin{verbatim}
(and (= (* 2 x) z) (= (+ (* 2 y) 1) z))
\end{verbatim}

The axiom \texttt{AndToOr} produces the equality
\[
(and (=\ (*\ 2\ x)\ z)\ (=\ (+\ (*\ 2\ y)\ 1)\ z)) =
(not (or (not (=\ (*\ 2\ x)\ z))\ (not (=\ (+\ (*\ 2\ y)\ 1)\ z))))
\]
which is the only rewrite step needed to transform the formula into canonical
form.  The rule \texttt{Eq} is then used to rewrite the input formula
into the canonical form
\[
(not\ (or\ (not\ (=\ (*\ 2\ x)\ z))\ (not\ (=\ (+\ (*\ 2\ y)\ 1)\ z))))\tag{canonical}\label{f:canonical}.
\]

Next, \si produces two clauses from this canonical form.  The first step in
this production is structural splitting of the negated or.  We will only
present the proof for the creation of a clause from the first ``conjunct''
since the steps for the second are similar.
\[
\inferrule*[Left=Eq,sep=.1em]{
  \inferrule*[left=NotOrElim]{(\ref{f:canonical})}{(not (not (= (*\ 2\ x) z)))}\\
  \inferrule*[left=NotSimp]{ }{(not (not (= (*\ 2\ x) z))) =
    (= (*\ 2\ x)\ z)}}
           {(=\ (*\ 2\ x)\ z)}
\]

Next, the rule \texttt{intern} produces the internal representation of the
atom.  Since we have a unit, the rule \texttt{clause} will not be used to
build the unit clause, and \si only applies \texttt{Eq}.
\[
\inferrule*[left=Eq]{(=\ (*\ 2\ x)\ z) \\
  \inferrule*[left=intern]{ }{(=\ (*\ 2\ x)\ z) = (=\ (+\ (*\ (-\ 2)\ x)\ z)\ 
    0)}}
           {(=\ (+\ (*\ (-\ 2)\ x)\ z)\ 0)}
\]

The whole proof then uses the unit clause just created and the unit clause
created for the second ``disjunct'' to conclude unsatisfiability of this
formula in linear integer arithmetic.  As mentioned above, we do not present
the complete proof here.  Instead, we show the part of the proof that
corresponds to the previous steps.
\begin{verbatim}
(@eq
  (@split
    (! 
     (@eq
      (@asserted (and (= (* 2 x) z) (= (+ (* 2 y) 1) z)))
      (@rewrite (! (= (and (= (* 2 x) z) (= (+ (* 2 y) 1) z))
          (not (or (not (= (* 2 x) z)) (not (= (+ (* 2 y) 1) z)))))
        :andToOr))
      ) :notOr)
    (not (not (= (* 2 x) z)))
  )
  (@trans
    (@rewrite (! (= (not (not (= (* 2 x) z))) (= (* 2 x) z)) :notSimp))
    (@intern (= (= (* 2 x) z) (! (= (+ z (* (- 2) x)) 0) :quoted)))))
\end{verbatim}

For a proof containing the rule \verb:flatten: and the \verb:@clause: function
simply use the formula $(A\lor(B\lor(C\lor\bot)))\land\lnot A\land\lnot
B\land\lnot C$.
\end{document}

%% Local Variables:
%% compile-command: "pdflatex -halt-on-error proof"
%% compilation-read-command: nil
%% End:
